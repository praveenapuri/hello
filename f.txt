{
  "schemaVersion": "0.3",
  "description": "Collect C: volume size/free (GB) from all Windows EC2s and consolidate outputs into one JSON file in S3.",
  "assumeRole": "{{ AutomationAssumeRole }}",
  "parameters": {
    "AutomationAssumeRole": {
      "type": "String",
      "description": "(Required) IAM role for Automation (must allow ssm:SendCommand, ssm:ListCommandInvocations, s3:GetObject, s3:ListBucket, s3:PutObject)."
    },
    "S3Bucket": {
      "type": "String",
      "description": "S3 bucket to store outputs."
    },
    "S3Prefix": {
      "type": "String",
      "description": "S3 key prefix (folder) for outputs, e.g. ssm/windows/diskfree",
      "default": "ssm/windows/diskfree"
    },
    "Region": {
      "type": "String",
      "default": "us-east-1",
      "description": "AWS Region for SendCommand and S3 ops."
    }
  },
  "mainSteps": [
    {
      "name": "RunDiskFreeOnWindows",
      "action": "aws:runCommand",
      "description": "Run PowerShell on all Windows instances and stream stdout to S3.",
      "inputs": {
        "DocumentName": "AWS-RunPowerShellScript",
        "InstanceIds": [],
        "Targets": [
          {
            "Key": "PlatformTypes",
            "Values": ["Windows"]
          }
        ],
        "Parameters": {
          "commands": [
            "$v = Get-Volume -DriveLetter C;",
            "$sizeGB = [math]::Round($v.Size/1GB,2);",
            "$freeGB = [math]::Round($v.SizeRemaining/1GB,2);",
            "$usedGB = [math]::Round($sizeGB - $freeGB,2);",
            "$pct = if ($sizeGB -gt 0) { [math]::Round(($freeGB / $sizeGB) * 100,2) } else { 0 };",
            "[pscustomobject]@{",
            "  Instance = $env:COMPUTERNAME;",
            "  Drive = 'C:';",
            "  SizeGB = $sizeGB;",
            "  UsedGB = $usedGB;",
            "  FreeGB = $freeGB;",
            "  FreePercent = $pct",
            "} | ConvertTo-Json -Compress"
          ]
        },
        "OutputS3BucketName": "{{ S3Bucket }}",
        "OutputS3KeyPrefix": "{{ S3Prefix }}",
        "ServiceRoleArn": "{{ AutomationAssumeRole }}"
      },
      "outputs": [
        {
          "Name": "CommandId",
          "Selector": "$.CommandId",
          "Type": "String"
        }
      ]
    },
    {
      "name": "WaitForCommandToComplete",
      "action": "aws:executeScript",
      "description": "Poll SSM until Run Command reaches a terminal state for all targets.",
      "inputs": {
        "Runtime": "python3.8",
        "Handler": "handler",
        "InputPayload": {
          "command_id": "{{ RunDiskFreeOnWindows.CommandId }}",
          "region": "{{ Region }}"
        },
        "Script": "import boto3, time\n\ndef handler(event, ctx):\n    ssm = boto3.client('ssm', region_name=event['region'])\n    cmd_id = event['command_id']\n    # Poll until command hits terminal state\n    terminal = {'Success', 'Cancelled', 'Failed', 'TimedOut', 'Incomplete'}\n    while True:\n        resp = ssm.list_commands(CommandId=cmd_id)\n        if not resp['Commands']:\n            time.sleep(2)\n            continue\n        status = resp['Commands'][0]['Status']\n        if status in terminal:\n            return {'status': status}\n        time.sleep(3)\n"
      }
    },
    {
      "name": "ConsolidateOutputsToS3",
      "action": "aws:executeScript",
      "description": "Download all per-instance stdout objects from S3, merge JSON, and upload a consolidated JSON file.",
      "inputs": {
        "Runtime": "python3.8",
        "Handler": "handler",
        "InputPayload": {
          "bucket": "{{ S3Bucket }}",
          "prefix": "{{ S3Prefix }}",
          "command_id": "{{ RunDiskFreeOnWindows.CommandId }}",
          "region": "{{ Region }}"
        },
        "Script": "import boto3, json\nfrom botocore.config import Config\n\ndef handler(event, ctx):\n    s3 = boto3.client('s3', config=Config(signature_version='s3v4'), region_name=event['region'])\n    bucket = event['bucket']\n    prefix = event['prefix'].rstrip('/')\n    cmd = event['command_id']\n    # SSM writes to: s3://bucket/prefix/CommandId/<instance-id>/awsrunPowerShellScript/0.aws:runPowerShellScript/stdout\n    base = f\"{prefix}/{cmd}/\"\n\n    # List all 'stdout' keys\n    keys = []\n    paginator = s3.get_paginator('list_objects_v2')\n    for page in paginator.paginate(Bucket=bucket, Prefix=base):\n        for obj in page.get('Contents', []):\n            k = obj['Key']\n            if k.endswith('/stdout'):\n                keys.append(k)\n\n    results = []\n    for k in keys:\n        body = s3.get_object(Bucket=bucket, Key=k)['Body'].read()\n        txt = body.decode('utf-8', errors='ignore').strip()\n        if not txt:\n            continue\n        try:\n            obj = json.loads(txt)\n            if isinstance(obj, list):\n                results.extend(obj)\n            else:\n                results.append(obj)\n        except Exception:\n            # If not valid JSON, wrap as raw\n            results.append({'raw': txt, 'source': k})\n\n    consolidated_key = f\"{prefix}/{cmd}/consolidated.json\"\n    s3.put_object(Bucket=bucket, Key=consolidated_key, Body=json.dumps(results, separators=(',', ':')).encode('utf-8'))\n    return {'ConsolidatedKey': consolidated_key, 'Count': len(results)}\n"
      },
      "outputs": [
        {
          "Name": "ConsolidatedKey",
          "Selector": "$.ConsolidatedKey",
          "Type": "String"
        },
        {
          "Name": "ItemCount",
          "Selector": "$.Count",
          "Type": "String"
        }
      ]
    }
  ],
  "outputs": [
    "RunDiskFreeOnWindows.CommandId",
    "ConsolidateOutputsToS3.ConsolidatedKey",
    "ConsolidateOutputsToS3.ItemCount"
  ]
}
